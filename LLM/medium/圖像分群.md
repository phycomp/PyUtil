torch影像 圖像分群
使用 PyTorch 進行影像的圖像分群（Clustering）可以通過結合深度學習和無監督學習來完成。在影像處理中，圖像分群可以應用於圖像分類、物件檢測和圖像分割等任務。常見的圖像分群方法包括：K-Means、層次聚類、DBSCAN 等。這裡我們結合 PyTorch 深度學習模型來提取特徵，然後使用 K-Means 分群作為範例。
步驟 1: 安裝必要庫
首先，確保安裝了以下依賴庫：
pip install torch torchvision matplotlib scikit-learn
步驟 2: 使用預訓練模型提取特徵
我們可以使用預訓練的卷積神經網絡（CNN）來提取影像特徵，例如 ResNet 或 VGG 模型。這些特徵將作為輸入，用於無監督的分群算法。
import torch
import torch.nn as nn
from torchvision import models, datasets, transforms
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans
import numpy as np

# 設置設備
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# 使用預訓練的 ResNet18 作為特徵提取器
model = models.resnet18(pretrained=True)
model = nn.Sequential(*list(model.children())[:-1])  # 移除最後的分類層
model = model.to(device)
model.eval()

# 圖像轉換
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

# 加載圖像數據集 (CIFAR-10)
dataset = datasets.CIFAR10(root='./data', train=True, transform=transform, download=True)
dataloader = torch.utils.data.DataLoader(dataset, batch_size=32, shuffle=False)

# 提取圖像特徵
def extract_features(dataloader, model):
    features = []
    with torch.no_grad():
        for images, _ in dataloader:
            images = images.to(device)
            outputs = model(images)
            outputs = outputs.view(outputs.size(0), -1)  # 展平特徵
            features.append(outputs.cpu().numpy())
    return np.concatenate(features)

# 提取特徵
features = extract_features(dataloader, model)
print("Features shape:", features.shape)  # 應該是 (N, 512)，N 為圖像數量

步驟 3: K-Means 分群
提取完特徵後，我們可以使用 K-Means 算法來對影像進行分群。
from sklearn.cluster import KMeans

# 設定分群數量 K
k = 10  # 例如分成10個群

# 使用 KMeans 進行分群
kmeans = KMeans(n_clusters=k, random_state=0)
clusters = kmeans.fit_predict(features)

print("Cluster assignments:", clusters)
步驟 4: 視覺化結果
我們可以將圖像按分群結果進行視覺化。這裡顯示每個群中的一些樣本圖像。
python
複製程式碼
def plot_images_by_cluster(dataset, clusters, cluster_id, num_images=5):
    fig, axes = plt.subplots(1, num_images, figsize=(12, 6))
    cluster_indices = np.where(clusters == cluster_id)[0][:num_images]
    
    for i, idx in enumerate(cluster_indices):
        image, _ = dataset[idx]
        image = image.permute(1, 2, 0).numpy() * 0.229 + 0.485  # 去標準化
        axes[i].imshow(np.clip(image, 0, 1))
        axes[i].axis('off')
    plt.show()

# 視覺化第0個群中的前5張圖像
plot_images_by_cluster(dataset, clusters, cluster_id=0)
完整流程
這是一個完整的影像分群流程，步驟概述如下：
    1. 使用預訓練的 ResNet18 提取每張圖像的特徵（影像的高維特徵向量）。
    2. 使用 K-Means 將這些高維特徵向量分成 k 個群。
    3. 根據分群結果對影像進行分類並視覺化。
進階優化
    1. 使用深度聚類算法：可以嘗試使用深度聚類方法，例如深度嵌入聚類（Deep Embedded Clustering, DEC），該方法通過聯合優化特徵提取與聚類目標來進行分群。
    2. 降維技術：在進行 K-Means 之前，可以使用降維技術如 PCA（主成分分析）或 t-SNE 將高維特徵壓縮到低維空間，這樣可能會提高分群效果。
    3. 自適應學習聚類中心：與使用預訓練模型和 K-Means 分群不同，可以考慮使用無監督學習方法來同時學習特徵和聚類中心，例如 DeepCluster。
這樣的分群模型可以進一步應用於影像檢索、場景識別、物件檢測等任務，尤其是在無標籤數據情況下，能夠幫助自動分類影像並揭示數據中的潛在結構。

通用dataset 依上述LLM的數學原理 取出features torch 進階範例
在大規模語言模型（LLM）的數學原理框架下，我們可以基於 PyTorch 的深度學習框架，從通用數據集中提取特徵。這些特徵可以用於無監督學習、聚類等進一步的應用場景。以下是使用 PyTorch 從通用數據集提取特徵的進階範例。
1. 數學原理回顧
LLM 和深度學習模型的特徵提取過程通常涉及神經網絡中的中間層激活，尤其是 CNN 或 Transformer 模型的高維隱藏層向量。在這裡，我們基於以下數學原理提取特徵：
    • 嵌入層（Embedding Layer）：將輸入映射到一個向量空間，用於處理離散輸入（如詞或圖片區域）。
    • 卷積層（Convolutional Layer）：用於圖像處理，卷積運算提取區域性的特徵。
    • 全連接層（Fully Connected Layer）：用於進一步處理提取到的高維特徵。
    • 注意力機制（Attention Mechanism）：在 Transformer 模型中，通過計算權重來提取重要特徵，這在序列數據處理中特別有效。
2. 框架概述
我們將構建一個通用的特徵提取流程，適用於各類數據集，包括影像、文本或其他結構化數據。此範例使用 PyTorch 的預訓練模型（如 ResNet、BERT）進行特徵提取。
3. 進階範例
我們使用 CIFAR-10 數據集和 ResNet 模型來示範如何從影像中提取特徵。對於文本數據，我們可以使用 BERT 或 GPT 來提取語言特徵。
步驟 1：安裝必要的庫
pip install torch torchvision transformers
步驟 2：載入預訓練模型進行特徵提取
這裡以影像為例，使用預訓練的 ResNet18 提取特徵；對於文本數據，則可以替換為 BERT 模型進行嵌入提取。
import torch
import torch.nn as nn
from torchvision import models, datasets, transforms
from torch.utils.data import DataLoader

# 設定設備
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# 使用預訓練的 ResNet 模型進行特徵提取
model = models.resnet18(pretrained=True)
model = nn.Sequential(*list(model.children())[:-1])  # 移除分類層，保留特徵提取部分
model = model.to(device)
model.eval()

# 定義影像數據轉換
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

# 加載 CIFAR-10 數據集
dataset = datasets.CIFAR10(root='./data', train=True, transform=transform, download=True)
dataloader = DataLoader(dataset, batch_size=32, shuffle=False)

# 提取圖像特徵
def extract_features(dataloader, model):
    features = []
    with torch.no_grad():
        for images, _ in dataloader:
            images = images.to(device)
            outputs = model(images)  # 通過 ResNet 模型提取特徵
            outputs = outputs.view(outputs.size(0), -1)  # 展平特徵向量
            features.append(outputs.cpu().numpy())
    return torch.tensor(features).squeeze(1)

# 提取數據集的特徵
features = extract_features(dataloader, model)
print("Features shape:", features.shape)  # (N, 512)，N 是數據集大小

步驟 3：文本特徵提取（使用 BERT）
如果你需要提取文本數據的特徵，可以使用 transformers 庫中的預訓練 BERT 模型來完成。
from transformers import BertTokenizer, BertModel

# 載入預訓練的 BERT 模型與 tokenizer
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
model = BertModel.from_pretrained('bert-base-uncased')
model = model.to(device)
model.eval()

# 定義文本數據
texts = ["This is a sample sentence.", "PyTorch is great for deep learning!"]

# Tokenize 文本
tokens = tokenizer(texts, padding=True, truncation=True, return_tensors="pt")
input_ids = tokens['input_ids'].to(device)
attention_mask = tokens['attention_mask'].to(device)

# 提取文本特徵
with torch.no_grad():
    outputs = model(input_ids, attention_mask=attention_mask)
    # 提取 [CLS] token 的嵌入作為句子特徵
    sentence_embeddings = outputs.last_hidden_state[:, 0, :]

print("Text features shape:", sentence_embeddings.shape)  # (N, 768)，N 是文本數量
4. 進階優化與應用
上述的特徵提取可以進一步用於其他無監督學習應用，例如：
    • 聚類分析（Clustering）：可以對提取到的影像或文本特徵進行 K-Means 聚類。
    • 降維（Dimensionality Reduction）：使用 PCA 或 t-SNE 降低特徵維度，進行可視化或更高效的分群分析。
    • 傳遞學習（Transfer Learning）：在自定義數據集上，使用預訓練模型提取特徵，然後在這些特徵上進行小規模訓練。
步驟 5：應用 K-Means 進行特徵聚類
python
複製程式碼
from sklearn.cluster import KMeans

# 使用 KMeans 進行特徵聚類
kmeans = KMeans(n_clusters=10, random_state=0)
cluster_labels = kmeans.fit_predict(features)

# 打印每個樣本的分群結果
print("Cluster labels:", cluster_labels)
5. 更多進階技術
    1. 多頭注意力機制（Multi-Head Attention）：可以在序列數據中使用 Transformer 模型提取注意力權重，分析序列中不同部分的重要性。
    2. 自適應聚類（Adaptive Clustering）：對於多模態數據（如圖像和文本的結合），可以使用多模態特徵來進行聯合聚類。
    3. 深度嵌入聚類（Deep Embedded Clustering, DEC）：進一步優化特徵提取的同時聯合學習聚類中心。
這樣的特徵提取與聚類方法可廣泛應用於多種無監督學習場景，從數據探索到預處理，再到進一步的分析和應用。
