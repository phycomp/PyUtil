圖像辦識 torch 進階範例
在 PyTorch 中進行圖像識別（Image Recognition）通常使用深度學習中的卷積神經網絡（Convolutional Neural Networks, CNNs）。這裡我們介紹一個進階範例，涵蓋以下部分：
    1. 使用預訓練模型（如 ResNet）進行圖像識別。
    2. 在自定義數據集上進行遷移學習（Transfer Learning）。
    3. 微調模型（Fine-Tuning）並進行訓練。
1. 安裝必要的庫
pip install torch torchvision matplotlib
2. 使用預訓練模型進行圖像識別
PyTorch 提供了許多預訓練模型，可以直接用於圖像識別任務，如 ResNet、VGG 等。我們將使用 ResNet18 來進行進階圖像識別任務。
步驟 1：加載預訓練的 ResNet 模型
首先，我們將下載並加載一個預訓練的 ResNet 模型，然後進行微調。
import torch
import torch.nn as nn
from torchvision import models, datasets, transforms
from torch.utils.data import DataLoader

# 設定設備
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# 使用預訓練的 ResNet18 模型
model = models.resnet18(pretrained=True)

# 替換最後的全連接層，適應自定義的分類數量（假設為 10 類）
num_classes = 10
model.fc = nn.Linear(model.fc.in_features, num_classes)

# 將模型移動到 GPU（如果可用）
model = model.to(device)
步驟 2：數據預處理
我們使用 CIFAR-10 數據集作為範例，並進行適當的數據預處理，包括圖像的縮放、轉換和歸一化。
# 定義圖像數據的轉換
transform = transforms.Compose([
    transforms.Resize((224, 224)),  # ResNet 的預設輸入大小為 224x224
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

# 加載 CIFAR-10 數據集
train_dataset = datasets.CIFAR10(root='./data', train=True, transform=transform, download=True)
test_dataset = datasets.CIFAR10(root='./data', train=False, transform=transform, download=True)

train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)
步驟 3：定義損失函數和優化器
我們使用交叉熵損失函數（Cross-Entropy Loss）來進行分類任務，並使用 Adam 優化器進行訓練。
# 定義損失函數和優化器
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
3. 模型微調與訓練
在微調（fine-tuning）過程中，我們會凍結（freeze）部分預訓練模型的層，並只對最後幾層進行訓練，這樣能夠保留預訓練模型的知識，同時適應新數據。
# 凍結所有層的參數，然後只訓練最後的全連接層
for param in model.parameters():
    param.requires_grad = False

# 只訓練最後的全連接層
for param in model.fc.parameters():
    param.requires_grad = True

# 訓練模型
num_epochs = 10

for epoch in range(num_epochs):
    model.train()
    running_loss = 0.0

    for images, labels in train_loader:
        images, labels = images.to(device), labels.to(device)

        # 前向傳播
        outputs = model(images)
        loss = criterion(outputs, labels)

        # 反向傳播與優化
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        running_loss += loss.item()

    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss / len(train_loader):.4f}')
4. 模型測試與評估
訓練完成後，我們在測試集上進行評估，以檢查模型的準確性。
# 測試模型
model.eval()  # 將模型設定為評估模式
correct = 0
total = 0

with torch.no_grad():
    for images, labels in test_loader:
        images, labels = images.to(device), labels.to(device)
        outputs = model(images)
        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()

print(f'Accuracy of the model on the test images: {100 * correct / total:.2f}%')
5. 進階優化
1. 動態調整學習率
可以使用學習率調度器（Learning Rate Scheduler）來隨著訓練進行動態調整學習率。
python
複製程式碼
scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)
for epoch in range(num_epochs):
    # 訓練模型
    # 更新學習率
    scheduler.step()
2. 更高級的正則化
可以加入 dropout 層或 L2 正則化，防止過擬合。
optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)  # 加入 L2 正則化
6. 使用自定義數據集進行遷移學習
如果有自己的數據集，可以使用以下步驟進行遷移學習：
步驟 1：準備自定義數據集
python
複製程式碼
from torchvision.datasets import ImageFolder

# 使用 ImageFolder 加載自定義圖像數據集
custom_dataset = ImageFolder(root='/path_to_custom_dataset', transform=transform)
custom_loader = DataLoader(custom_dataset, batch_size=32, shuffle=True)
步驟 2：重複上述的訓練過程
使用自定義數據集代替 CIFAR-10，並執行微調與訓練過程。
總結
這是一個進階的圖像識別範例，涵蓋了：
    • 如何使用 PyTorch 的預訓練模型進行遷移學習和微調。
    • 如何對圖像數據進行預處理。
    • 如何在自定義數據集上進行訓練與測試。
你可以根據具體需求選擇不同的預訓練模型（如 ResNet、VGG、EfficientNet），並進一步對模型進行優化。
